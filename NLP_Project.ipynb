{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13906,"status":"ok","timestamp":1744707149343,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"1NsGHUW0sSYQ","outputId":"5745e6b6-9f27-4336-8611-2831192a8673"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy~=1.26.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Requirement already satisfied: numpy\u003e=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: scipy\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers\u003c0.22,\u003e=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors\u003e=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1-\u003etorch) (1.3.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard\u003c2.19,\u003e=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes\u003c0.5.0,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (3.4.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (2.3.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003etransformers) (2025.1.31)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-\u003etorch) (3.0.2)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (0.1.2)\n","Requirement already satisfied: rich~=13.0 in /usr/local/lib/python3.11/dist-packages (13.9.4)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich~=13.0) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich~=13.0) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich~=13.0) (0.1.2)\n","--- Checking Key Package Versions ---\n","nltk                                  3.9.1\n","numpy                                 1.26.4\n","rich                                  13.9.4\n","tensorflow                            2.18.0\n","tensorflow-datasets                   4.9.8\n","tensorflow_decision_forests           1.11.0\n","tensorflow-hub                        0.16.1\n","tensorflow-io-gcs-filesystem          0.37.1\n","tensorflow-metadata                   1.17.0\n","tensorflow-probability                0.25.0\n","tensorflow-text                       2.18.1\n","--- Check Complete ---\n","\n"," *** IMPORTANT: Dependencies installed/updated. Please RESTART RUNTIME now (Runtime -\u003e Restart runtime) before running subsequent cells! *** \n","\n","Downloading NLTK resources ('punkt', 'stopwords')...\n","NLTK resources downloaded successfully.\n","Core libraries imported.\n","Using python-telegram-bot version: 20.3\n","NLTK ready (for basic tokenization): True\n"]}],"source":["# Run this cell in Colab\n","\n","# --- Install Libraries ---\n","!pip install numpy~=1.26.0 # Pin NumPy first\n","!pip install pandas nltk scikit-learn transformers torch tensorflow sentencepiece\n","# No VADER needed now\n","!pip install rich~=13.0 # Downgrade rich\n","\n","# --- Check final versions ---\n","print(\"--- Checking Key Package Versions ---\")\n","!pip list | grep -E 'numpy|tensorflow|nltk|rich' # Removed vader/spacy\n","print(\"--- Check Complete ---\")\n","\n","# --- IMPORTANT: RESTART RUNTIME AFTER THIS CELL ---\n","print(\"\\n *** IMPORTANT: Dependencies installed/updated. Please RESTART RUNTIME now (Runtime -\u003e Restart runtime) before running subsequent cells! *** \\n\")\n","\n","# --- Code below will run AFTER restart ---\n","\n","import pandas as pd\n","import numpy as np\n","import nltk # Still needed for tokenization in summarizer fallback\n","import re\n","import string\n","# import collections # Not needed if Pro/Con is removed\n","import logging\n","import time\n","\n","# --- NLTK Download (Minimal: punkt for tokenization, stopwords) ---\n","print(\"Downloading NLTK resources ('punkt', 'stopwords')...\")\n","NLTK_READY = False # Flag for basic NLTK\n","try:\n","    nltk.download('punkt', quiet=True) # Needed for sent_tokenize fallback in summarizer\n","    nltk.download('stopwords', quiet=True) # Might be used elsewhere, keep for now\n","    print(\"NLTK resources downloaded successfully.\")\n","    stop_words = set(stopwords.words('english')) # Keep stopwords just in case\n","    NLTK_READY = True\n","except Exception as e:\n","    print(f\"Error downloading NLTK data: {e}\")\n","    stop_words = set()\n","    # NLTK_READY remains False\n","# --- End NLTK Download ---\n","\n","# --- VADER Setup (REMOVED) ---\n","# No VADER needed\n","\n","# --- Core Library Imports ---\n","from transformers import pipeline\n","import torch\n","import telegram\n","from telegram.ext import Application, CommandHandler, MessageHandler, filters\n","# --- End Core Library Imports ---\n","\n","# Setup logging for the bot\n","logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"Core libraries imported.\")\n","print(f\"Using python-telegram-bot version: {telegram.__version__}\")\n","print(f\"NLTK ready (for basic tokenization): {NLTK_READY}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678,"status":"ok","timestamp":1744707174999,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"9GUH7sQIvUSo","outputId":"d18bb8a0-4673-4087-fe26-e86d39008d48"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Block 1: Loading Data ---\n","Dataset loaded successfully. Shape: (205052, 6)\n","Columns found: ['product_name', 'product_price', 'Rate', 'Review', 'Summary', 'Sentiment']\n","Data loaded and basic preparation done.\n","\n","Sample Data (including Summary):\n","                                        product_name           Review  Rate  \\\n","0  Candes 12 L Room/Personal Air Cooler??????(Whi...           super!   5.0   \n","1  Candes 12 L Room/Personal Air Cooler??????(Whi...          awesome   5.0   \n","2  Candes 12 L Room/Personal Air Cooler??????(Whi...             fair   3.0   \n","3  Candes 12 L Room/Personal Air Cooler??????(Whi...  useless product   1.0   \n","4  Candes 12 L Room/Personal Air Cooler??????(Whi...             fair   3.0   \n","\n","  Sentiment                                            Summary  \n","0  positive  great cooler excellent air flow and for this p...  \n","1  positive              best budget 2 fit cooler nice cooling  \n","2  positive  the quality is good but the power of air is de...  \n","3  negative                  very bad product its a only a fan  \n","4   neutral                                      ok ok product  \n","--- Block 1: Complete ---\n"]}],"source":["# %% [code]\n","# Block 1: Load and Prepare Data\n","\n","print(\"\\n--- Block 1: Loading Data ---\")\n","# --- Configuration ---\n","DATA_FILE = 'Dataset-SA.csv' # Make sure this file is uploaded to Colab session storage\n","PRODUCT_NAME_COLUMN = 'product_name'\n","REVIEW_TEXT_COLUMN = 'Review'\n","RATING_COLUMN = 'Rate'\n","ORIGINAL_SENTIMENT_COLUMN = 'Sentiment'\n","SUMMARY_COLUMN = 'Summary' # \u003c-- ADDED: Column name for original summaries\n","\n","# --- Load Data ---\n","df = None\n","try:\n","    df = pd.read_csv(DATA_FILE)\n","    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n","    print(\"Columns found:\", df.columns.tolist())\n","\n","    # Verify required columns exist (including the new SUMMARY_COLUMN)\n","    required_columns = [PRODUCT_NAME_COLUMN, REVIEW_TEXT_COLUMN, RATING_COLUMN, ORIGINAL_SENTIMENT_COLUMN, SUMMARY_COLUMN]\n","    if not all(col in df.columns for col in required_columns):\n","        missing = [col for col in required_columns if col not in df.columns]\n","        raise ValueError(f\"Missing required columns: {missing}. Found: {df.columns.tolist()}\")\n","\n","    # Basic Data Cleaning \u0026 Type Conversion\n","    df.dropna(subset=[REVIEW_TEXT_COLUMN], inplace=True) # Drop rows with no review text\n","    df[REVIEW_TEXT_COLUMN] = df[REVIEW_TEXT_COLUMN].astype(str)\n","    df[PRODUCT_NAME_COLUMN] = df[PRODUCT_NAME_COLUMN].astype(str)\n","    # Convert Rating, coerce errors to NaN\n","    df[RATING_COLUMN] = pd.to_numeric(df[RATING_COLUMN], errors='coerce')\n","    # Clean Sentiment column\n","    if ORIGINAL_SENTIMENT_COLUMN in df.columns:\n","         df[ORIGINAL_SENTIMENT_COLUMN] = df[ORIGINAL_SENTIMENT_COLUMN].astype(str).str.lower().str.strip()\n","    # Clean Summary column - Ensure string, fill NaN with empty string, strip whitespace\n","    if SUMMARY_COLUMN in df.columns:\n","        df[SUMMARY_COLUMN] = df[SUMMARY_COLUMN].astype(str).fillna('').str.strip()\n","\n","    print(\"Data loaded and basic preparation done.\")\n","    print(\"\\nSample Data (including Summary):\")\n","    print(df[required_columns].head())\n","\n","except FileNotFoundError:\n","    print(f\"ERROR: File '{DATA_FILE}' not found. Please upload it to your Colab environment.\")\n","    df = None # Ensure df is None if loading fails\n","except ValueError as e:\n","    print(f\"ERROR: {e}\")\n","    df = None\n","except Exception as e:\n","    print(f\"An unexpected error occurred loading the data: {e}\")\n","    df = None\n","\n","print(\"--- Block 1: Complete ---\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1744707180147,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"AWS9yKFnvlWQ","outputId":"9030cdfc-4325-494e-bc78-89eefd87d3ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using RELAXED V2 Heuristics for fake review detection.\n","\n","--- RELAXED V2 Heuristic Tests ---\n","Running tests with sample data...\n","  Test: ('amazing product works perfectly !!!!!', Rate: 5, Sent: Positive) -\u003e Predicted Fake: True - INCORRECT (Expected False)\n","  Test: ('Bad.', Rate: 1, Sent: Negative) -\u003e Predicted Fake: True - INCORRECT (Expected False)\n","  Test: ('Ok', Rate: 3, Sent: Neutral) -\u003e Predicted Fake: True - Correct\n","  Test: ('.', Rate: 1, Sent: Negative) -\u003e Predicted Fake: True - Correct\n","  Test: ('Good', Rate: 4, Sent: Positive) -\u003e Predicted Fake: True - Correct\n","  Test: ('Good product', Rate: 4, Sent: Positive) -\u003e Predicted Fake: False - Correct\n","  Test: ('Absolutely terrible product, do not buy.', Rate: 5, Sent: Negative) -\u003e Predicted Fake: True - Correct\n","  Test: ('GOOD PRODUCT', Rate: 4, Sent: Positive) -\u003e Predicted Fake: False - Correct\n","  Test: ('THIS IS A LONGER REVIEW ALL IN CAPS', Rate: 5, Sent: Positive) -\u003e Predicted Fake: True - Correct\n","  Test: ('it was okay', Rate: 3, Sent: Neutral) -\u003e Predicted Fake: False - Correct\n","  Test: ('This is fantastic, I love it!', Rate: 1, Sent: Positive) -\u003e Predicted Fake: True - Correct\n","  Test: ('vvvvvvveeeeerrrryyyyy goooood', Rate: 5, Sent: Positive) -\u003e Predicted Fake: True - Correct\n","  Test: ('Great!', Rate: 5, Sent: Positive) -\u003e Predicted Fake: True - Correct\n","  Test: ('Didn't work.', Rate: 1, Sent: Negative) -\u003e Predicted Fake: False - Correct\n","Accuracy on test cases: 85.7%\n","--- End Heuristic Tests ---\n"]}],"source":["# %% [code]\n","# STEP 2 CODE BLOCK (COMPLETE - RELAXED HEURISTICS V2)\n","\n","import pandas as pd # Make sure pandas is imported\n","import re          # Make sure re is imported\n","import logging     # Make sure logging is imported\n","\n","logger = logging.getLogger(__name__) # Ensure logger is defined\n","\n","# --- Fake Review Detection (RELAXED Heuristic Approach V2) ---\n","\n","def predict_fake_heuristic(review_text, rating, original_sentiment):\n","    \"\"\"\n","    RELAXED heuristic rules using text, rating, and original sentiment.\n","    Aims to filter only the most obvious spam/junk.\n","    Returns True if suspected fake, False otherwise.\n","    \"\"\"\n","    text = str(review_text).strip() # Ensure text is string and stripped\n","    # Normalize original sentiment for comparison (handle potential NaN/None)\n","    sentiment = str(original_sentiment).lower().strip() if pd.notna(original_sentiment) else None\n","    rate = rating if pd.notna(rating) else None\n","\n","    # --- Rule Tuning - Be VERY lenient ---\n","\n","    # Rule 1: Very short reviews - **Significantly Relaxed**\n","    # Only flag reviews with virtually no content.\n","    if len(text.split()) \u003c 2: # Was \u003c 4, now \u003c 2 (e.g., flags \"Ok\", \".\", but allows \"Good product\")\n","        logger.info(f\"Flagged as potentially fake (Rule 1: Too short - {len(text.split())} words): '{text[:50]}...'\")\n","        return True\n","\n","    # Rule 2: Excessive capitalization - Keep (Relatively reliable signal)\n","    # Check only if text is reasonably long\n","    if len(text) \u003e 30 and sum(1 for c in text if c.isupper()) / len(text) \u003e 0.6: # Threshold slightly increased\n","         logger.info(f\"Flagged as potentially fake (Rule 2: Excessive Caps): '{text[:50]}...'\")\n","         return True\n","\n","    # Rule 3: Excessive punctuation - Keep, maybe relax threshold slightly? Let's keep 5+\n","    if len(re.findall(r'(!|\\?){5,}', text)) \u003e 0: # 5+ consecutive ! or ?\n","        logger.info(f\"Flagged as potentially fake (Rule 3: Excessive Punctuation): '{text[:50]}...'\")\n","        return True\n","\n","    # Rule 4: Repetitive characters - Keep (Good signal)\n","    if len(re.findall(r'(.)\\1{4,}', text)) \u003e 0: # 5+ consecutive identical characters\n","        logger.info(f\"Flagged as potentially fake (Rule 4: Repetitive Chars): '{text[:50]}...'\")\n","        return True\n","\n","    # Rule 5/6: Mismatch - Keep (Clear contradictions are strong signals)\n","    if rate is not None and sentiment is not None:\n","        # Rule 5: Low rating (1 star) but explicitly 'positive' sentiment\n","        if rate == 1 and sentiment == 'positive':\n","            logger.info(f\"Flagged as potentially fake (Rule 5: Rating/Sentiment Mismatch - Rate 1, Sent 'positive'): '{text[:50]}...'\")\n","            return True\n","        # Rule 6: High rating (5 stars) but explicitly 'negative' sentiment\n","        if rate == 5 and sentiment == 'negative':\n","            logger.info(f\"Flagged as potentially fake (Rule 6: Rating/Sentiment Mismatch - Rate 5, Sent 'negative'): '{text[:50]}...'\")\n","            return True\n","\n","    # Rule 7: Generic phrases - Keep commented out\n","\n","    # Rule 8: All Caps Review - Keep (Good signal)\n","    if text.isupper() and len(text) \u003e 20:\n","        logger.info(f\"Flagged as potentially fake (Rule 8: All Caps): '{text[:50]}...'\")\n","        return True\n","\n","    # --- If none of the above rules triggered ---\n","    return False # Assume genuine\n","\n","\n","# --- Assign the chosen function ---\n","is_likely_fake = predict_fake_heuristic\n","print(\"Using RELAXED V2 Heuristics for fake review detection.\")\n","\n","# --- Test the heuristic function (Examples - Adjusted Expectations) ---\n","print(\"\\n--- RELAXED V2 Heuristic Tests ---\")\n","test_data = [\n","    # Text, Rating, Original Sentiment, Expected Fake (True/False) with RELAXED V2 rules\n","    (\"amazing product works perfectly !!!!!\", 5, 'Positive', False), # Should pass (punctuation ok)\n","    (\"Bad.\", 1, 'Negative', False), # Should PASS now (\u003e= 1 word)\n","    (\"Ok\", 3, 'Neutral', True), # Should FAIL now (\u003c 2 words)\n","    (\".\", 1, 'Negative', True), # Should FAIL (\u003c 2 words)\n","    (\"Good\", 4, 'Positive', True), # Should FAIL (\u003c 2 words)\n","    (\"Good product\", 4, 'Positive', False), # Should PASS (\u003e= 2 words)\n","    (\"Absolutely terrible product, do not buy.\", 5, 'Negative', True), # Should still fail (Rule 6: Rate 5/Negative)\n","    (\"GOOD PRODUCT\", 4, 'Positive', False), # Should pass (Not all caps \u003e 20 chars)\n","    (\"THIS IS A LONGER REVIEW ALL IN CAPS\", 5, 'Positive', True), # Should fail (Rule 8: All Caps \u003e 20 chars)\n","    (\"it was okay\", 3, 'Neutral', False), # Should pass\n","    (\"This is fantastic, I love it!\", 1, 'Positive', True), # Should fail (Rule 5: Rate 1/Positive)\n","    (\"vvvvvvveeeeerrrryyyyy goooood\", 5, 'Positive', True), # Should fail (Rule 4: Repetitive chars \u003e= 5)\n","    (\"Great!\", 5, 'Positive', True), # Should FAIL (\u003c 2 words)\n","    (\"Didn't work.\", 1, 'Negative', False) # Should pass (\u003e= 2 words)\n","]\n","\n","# Check if DataFrame 'df' exists before running detailed tests (optional here)\n","run_detailed_tests = True # Assume we want to see test output\n","\n","if run_detailed_tests:\n","    print(\"Running tests with sample data...\")\n","    correct_count = 0\n","    for text, rating, sentiment, expected in test_data:\n","        is_fake = is_likely_fake(text, rating, sentiment)\n","        status = \"Correct\" if is_fake == expected else f\"INCORRECT (Expected {expected})\"\n","        if is_fake == expected: correct_count += 1\n","        print(f\"  Test: ('{text}', Rate: {rating}, Sent: {sentiment}) -\u003e Predicted Fake: {is_fake} - {status}\")\n","    print(f\"Accuracy on test cases: {correct_count / len(test_data):.1%}\")\n","else:\n","    print(\"Skipping detailed heuristic tests.\")\n","\n","print(\"--- End Heuristic Tests ---\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2250,"status":"ok","timestamp":1744707187760,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"gdiev5T5v2DY","outputId":"cd299264-e277-4baa-f8aa-79ceb6c5b407"},"outputs":[{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["Sentiment analysis pipeline loaded (RoBERTa) on device: CPU.\n","\n","--- Sentiment Analysis Tests ---\n","Test Positive ('This product is amazing, I really love it!'): {'label': 'Positive', 'score': 0.9926257729530334}\n","Test Negative ('Worst purchase ever, completely broke after one day.'): {'label': 'Negative', 'score': 0.9672914743423462}\n","Test Neutral ('The product is black.'): {'label': 'Neutral', 'score': 0.5029102563858032}\n","--- End Sentiment Analysis Tests ---\n"]}],"source":["# --- Sentiment Analysis Setup (Hugging Face) ---\n","\n","sentiment_pipeline = None\n","try:\n","    # Using a model that outputs Positive/Negative/Neutral directly\n","    # Consider device='cuda' if GPU is available in Colab runtime, otherwise defaults to CPU\n","    device = 0 if torch.cuda.is_available() else -1\n","    sentiment_pipeline = pipeline(\n","        \"sentiment-analysis\",\n","        model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n","        device=device # Use GPU if available\n","        )\n","    print(f\"Sentiment analysis pipeline loaded (RoBERTa) on device: {'GPU' if device == 0 else 'CPU'}.\")\n","\n","    def get_sentiment(review_text):\n","        \"\"\"Analyzes sentiment using the loaded pipeline.\"\"\"\n","        if not sentiment_pipeline:\n","             return {\"label\": \"Neutral\", \"score\": 0.0}\n","        try:\n","            # Model has max sequence length, truncation is handled by pipeline by default usually\n","            # but explicit truncation can prevent unexpected errors with very long reviews.\n","            max_length = 512\n","            truncated_text = review_text[:max_length*4] # Allow slightly longer input for truncation handling\n","\n","            if not truncated_text.strip(): # Handle empty strings\n","                return {\"label\": \"Neutral\", \"score\": 0.0}\n","\n","            with torch.no_grad(): # Disable gradient calculation for inference\n","                 result = sentiment_pipeline(truncated_text, truncation=True)[0] # Ensure truncation\n","\n","            # Map labels (LABEL_0: Negative, LABEL_1: Neutral, LABEL_2: Positive)\n","            label_map = {\"LABEL_0\": \"Negative\", \"LABEL_1\": \"Neutral\", \"LABEL_2\": \"Positive\"}\n","            sentiment = label_map.get(result['label'], \"Neutral\")\n","            score = result['score']\n","            return {\"label\": sentiment, \"score\": score}\n","        except Exception as e:\n","            logger.error(f\"Error during sentiment analysis for text: '{review_text[:50]}...': {e}\")\n","            return {\"label\": \"Neutral\", \"score\": 0.0} # Default on error\n","\n","except Exception as e:\n","    print(f\"ERROR loading sentiment pipeline: {e}\")\n","    print(\"Sentiment analysis may not be available or will be slow (CPU fallback).\")\n","    # Define a dummy function if pipeline fails\n","    def get_sentiment(review_text):\n","        logger.warning(\"Sentiment pipeline not loaded, returning Neutral.\")\n","        return {\"label\": \"Neutral\", \"score\": 0.0}\n","\n","# --- Test Sentiment Analysis ---\n","print(\"\\n--- Sentiment Analysis Tests ---\")\n","if sentiment_pipeline:\n","    test_review_pos = \"This product is amazing, I really love it!\"\n","    sentiment_result_pos = get_sentiment(test_review_pos)\n","    print(f\"Test Positive ('{test_review_pos}'): {sentiment_result_pos}\")\n","\n","    test_review_neg = \"Worst purchase ever, completely broke after one day.\"\n","    sentiment_result_neg = get_sentiment(test_review_neg)\n","    print(f\"Test Negative ('{test_review_neg}'): {sentiment_result_neg}\")\n","\n","    test_review_neu = \"The product is black.\"\n","    sentiment_result_neu = get_sentiment(test_review_neu)\n","    print(f\"Test Neutral ('{test_review_neu}'): {sentiment_result_neu}\")\n","else:\n","    print(\"Skipping sentiment analysis test as pipeline failed to load.\")\n","print(\"--- End Sentiment Analysis Tests ---\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17196,"status":"ok","timestamp":1744707210288,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"BoMpyYz5wA_Y","outputId":"e5e3f6cf-8a0d-400d-86cc-adfe560b4f0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["Summarization pipeline loaded (DistilBART) on device: CPU.\n","\n","--- Summarization Test ---\n","Input Text Length: 797 chars\n","Generated Summary:  Review 1: This is the first review . It was okay, not great but not terrible . Decent for the price point . Buttons feel a bit flimsy .\n","--- End Summarization Test ---\n"]}],"source":["# %% [code]\n","# STEP 4 CODE BLOCK (Ensure this runs successfully before Block 6)\n","\n","# --- Summarization Setup (Hugging Face) ---\n","summarizer = None\n","try:\n","    # Ensure torch is imported from Block 0!\n","    # Consider device='cuda' if GPU is available\n","    device = 0 if torch.cuda.is_available() else -1\n","    summarizer = pipeline(\n","        \"summarization\",\n","        model=\"sshleifer/distilbart-cnn-12-6\",\n","        device=device # Use GPU if available\n","        )\n","    print(f\"Summarization pipeline loaded (DistilBART) on device: {'GPU' if device == 0 else 'CPU'}.\")\n","\n","    def generate_summary(text_corpus, max_len=130, min_len=25): # Adjusted lengths\n","        \"\"\"Generates a summary from a large block of text.\"\"\"\n","        if not summarizer:\n","            logger.warning(\"Summarizer pipeline accessed but not loaded.\")\n","            # Fallback: Return first few sentences if summarizer fails\n","            sentences = re.split(r'(?\u003c=[.!?])\\s+', text_corpus) # Need import re\n","            return \" \".join(sentences[:3]) + \"...\" if sentences else \"Summarization unavailable.\"\n","        try:\n","            # Summarization models have input length limits (e.g., 1024 tokens for BART)\n","            # Pipelines often handle this, but being explicit can help.\n","            # Let's estimate max chars based on typical token length\n","            max_input_chars = 1024 * 4 # Heuristic limit (adjust based on model/memory)\n","\n","            # Ensure input is string and not empty\n","            text_to_summarize = str(text_corpus).strip()\n","            if not text_to_summarize:\n","                 return \"No genuine reviews available to summarize.\"\n","\n","            truncated_corpus = text_to_summarize[:max_input_chars]\n","\n","            with torch.no_grad(): # Disable gradient calculation\n","                # Use truncation=True in the call\n","                summary_list = summarizer(truncated_corpus, max_length=max_len, min_length=min_len, do_sample=False, truncation=True)\n","\n","            # Check if the result is valid\n","            if summary_list and isinstance(summary_list, list) and 'summary_text' in summary_list[0]:\n","                 return summary_list[0]['summary_text']\n","            else:\n","                 logger.error(f\"Unexpected summarizer output format: {summary_list}\")\n","                 return \"Could not generate summary (unexpected output).\"\n","\n","        except Exception as e:\n","            logger.error(f\"Error during summarization: {e}\")\n","            # Fallback: Return first few sentences if summarizer fails\n","            sentences = re.split(r'(?\u003c=[.!?])\\s+', str(text_corpus)) # Need import re\n","            return \" \".join(sentences[:3]) + \"...\" if sentences else \"Could not generate summary (error).\"\n","\n","except NameError as ne:\n","     print(f\"ERROR loading summarization pipeline: {ne}\")\n","     print(\"This usually means 'import torch' or 'import re' in Block 0 was not executed in this session.\")\n","     print(\"Please re-run Block 0, then Blocks 1-3, and this block (4) again.\")\n","     # Define dummy function\n","     def generate_summary(text_corpus, max_len=130, min_len=25):\n","        logger.warning(\"Summarizer pipeline not loaded (NameError), using fallback.\")\n","        try:\n","            sentences = re.split(r'(?\u003c=[.!?])\\s+', str(text_corpus)) # Need import re\n","            return \" \".join(sentences[:3]) + \"...\" if sentences else \"Summarization unavailable.\"\n","        except NameError: # If re wasn't imported\n","             return \"Summarization unavailable (re module missing).\"\n","except Exception as e:\n","    print(f\"ERROR loading summarization pipeline: {e}\")\n","    print(\"Summarization may not be available or will use basic fallback.\")\n","    # Define a dummy function if pipeline fails for other reasons\n","    def generate_summary(text_corpus, max_len=130, min_len=25):\n","         logger.warning(f\"Summarizer pipeline not loaded (Error: {e}), using fallback.\")\n","         try:\n","            sentences = re.split(r'(?\u003c=[.!?])\\s+', str(text_corpus)) # Need import re\n","            return \" \".join(sentences[:3]) + \"...\" if sentences else \"Summarization unavailable.\"\n","         except NameError: # If re wasn't imported\n","             return \"Summarization unavailable (re module missing).\"\n","         except Exception as fallback_e:\n","             logger.error(f\"Error in summarizer fallback: {fallback_e}\")\n","             return \"Summarization unavailable (fallback error).\"\n","\n","\n","# --- Test Summarization ---\n","print(\"\\n--- Summarization Test ---\")\n","long_text_example = \"\"\"\n","Review 1: This is the first review. It was okay, not great but not terrible. The setup was easy. Buttons feel a bit flimsy. Decent for the price point.\n","Review 2: This second review is much more positive. I absolutely love this product! It exceeded all my expectations and works flawlessly. Highly recommended to everyone needing this. Setup was instant.\n","Review 3: A third opinion suggests mediocrity. It does the job, but feels a bit cheap, like it might break soon. I wouldn't buy it again at full price. Maybe wait for a sale if you really need one. Performance is average.\n","Review 4: Finally, a very negative experience. Broke within a week of light use. Customer service was unhelpful and slow to respond. Avoid this product at all costs. It's flimsy and poorly made. Complete waste of money.\n","\"\"\"\n","# Use the defined generate_summary function (real or dummy)\n","summary_result = generate_summary(long_text_example)\n","print(f\"Input Text Length: {len(long_text_example)} chars\")\n","print(f\"Generated Summary: {summary_result}\")\n","print(\"--- End Summarization Test ---\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":631,"status":"ok","timestamp":1744707214975,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"nTQuVk8ZwBAj","outputId":"658cf250-1dbe-4c1a-d872-eafe4a365da5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Verdict Logic Tests ---\n","Test: ['Positive', 'Positive', 'Negative', 'Neutral', 'Positive', 'Positive'] -\u003e Verdict: 'Generally Positive üôÇ' (Expected: 'Generally Positive üôÇ') - Correct\n","Test: ['Negative', 'Negative', 'Negative', 'Neutral', 'Positive'] -\u003e Verdict: 'Generally Negative üôÅ' (Expected: 'Generally Negative üôÅ') - Correct\n","Test: ['Positive', 'Negative', 'Positive', 'Negative', 'Neutral', 'Neutral', 'Neutral'] -\u003e Verdict: 'Neutral / Balanced üòê' (Expected: 'Neutral / Balanced üòê') - Correct\n","Test: ['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Neutral'] -\u003e Verdict: 'Overwhelmingly Positive üëç' (Expected: 'Overwhelmingly Positive üëç') - Correct\n","Test: ['Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Neutral'] -\u003e Verdict: 'Overwhelmingly Negative üëé' (Expected: 'Overwhelmingly Negative üëé') - Correct\n","Test: ['Positive', 'Negative'] -\u003e Verdict: 'Mixed Reviews ü§î' (Expected: 'Mixed Reviews ü§î') - Correct\n","Test: [] -\u003e Verdict: 'Not Enough Data' (Expected: 'Not Enough Data') - Correct\n","--- End Verdict Logic Tests ---\n"]}],"source":["# --- Verdict Calculation Logic ---\n","\n","def calculate_overall_verdict(sentiments):\n","    \"\"\"\n","    Calculates an overall verdict based on a list of *newly generated* sentiment labels.\n","    Args:\n","        sentiments (list): A list of sentiment labels ('Positive', 'Negative', 'Neutral').\n","    Returns:\n","        str: The overall verdict.\n","    \"\"\"\n","    if not sentiments:\n","        return \"Not Enough Data\"\n","\n","    total = len(sentiments)\n","    pos_count = sentiments.count(\"Positive\")\n","    neg_count = sentiments.count(\"Negative\")\n","    neu_count = sentiments.count(\"Neutral\")\n","\n","    # --- Define Verdict Logic (Adjust thresholds as needed) ---\n","    pos_ratio = pos_count / total\n","    neg_ratio = neg_count / total\n","\n","    if pos_ratio \u003e= 0.65 and neg_ratio \u003c 0.15:\n","        return \"Overwhelmingly Positive üëç\"\n","    elif pos_ratio \u003e neg_ratio + 0.15 and pos_ratio \u003e= 0.40: # Clearly more positive than negative\n","        return \"Generally Positive üôÇ\"\n","    elif neg_ratio \u003e= 0.65 and pos_ratio \u003c 0.15:\n","        return \"Overwhelmingly Negative üëé\"\n","    elif neg_ratio \u003e pos_ratio + 0.15 and neg_ratio \u003e= 0.40: # Clearly more negative than positive\n","        return \"Generally Negative üôÅ\"\n","    elif abs(pos_ratio - neg_ratio) \u003c 0.20 and neu_count \u003c 0.5: # Relatively balanced Pos/Neg\n","        return \"Mixed Reviews ü§î\"\n","    else: # Default to Neutral if high neutral count or roughly equal pos/neg\n","        return \"Neutral / Balanced üòê\"\n","\n","# --- Test Verdict Logic ---\n","print(\"\\n--- Verdict Logic Tests ---\")\n","test_cases = [\n","    ([\"Positive\", \"Positive\", \"Negative\", \"Neutral\", \"Positive\", \"Positive\"], \"Generally Positive üôÇ\"),\n","    ([\"Negative\", \"Negative\", \"Negative\", \"Neutral\", \"Positive\"], \"Generally Negative üôÅ\"),\n","    ([\"Positive\", \"Negative\", \"Positive\", \"Negative\", \"Neutral\", \"Neutral\", \"Neutral\"], \"Neutral / Balanced üòê\"),\n","    ([\"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Neutral\"], \"Overwhelmingly Positive üëç\"),\n","    ([\"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Negative\", \"Neutral\"], \"Overwhelmingly Negative üëé\"),\n","    ([\"Positive\", \"Negative\"], \"Mixed Reviews ü§î\"),\n","    ([], \"Not Enough Data\")\n","]\n","for sentiments, expected in test_cases:\n","    verdict = calculate_overall_verdict(sentiments)\n","    status = \"Correct\" if verdict == expected else \"INCORRECT\"\n","    print(f\"Test: {sentiments} -\u003e Verdict: '{verdict}' (Expected: '{expected}') - {status}\")\n","print(\"--- End Verdict Logic Tests ---\")"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1744707245063,"user":{"displayName":"Sure Gowtham","userId":"08759616473142872523"},"user_tz":-330},"id":"1HraJhdbwXi1"},"outputs":[],"source":["# %% [code]\n","# STEP 6 CODE BLOCK (REMOVED Pro/Con Extraction \u0026 Output)\n","\n","import asyncio\n","import re\n","import traceback\n","import numpy as np\n","import pandas as pd\n","# import collections # Not needed now\n","import time\n","import nltk # Keep for summarizer fallback\n","\n","# --- Helper for MarkdownV2 Escaping ---\n","def escape_markdown_v2(text):\n","    \"\"\"Escapes characters for Telegram MarkdownV2 parse mode.\"\"\"\n","    escape_chars = r'_*[]()~`\u003e#+-=|{}.!'\n","    text = str(text).replace('\\\\', '\\\\\\\\')\n","    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\\\\1', text)\n","\n","# --- Telegram Bot Configuration ---\n","BOT_TOKEN = \"7999899637:AAFCTDaI0eu8RhCmZZjpkfTBu45NxmZPi1E\" # Use your actual token\n","\n","# --- Pro/Con Extraction Function (REMOVED) ---\n","# No extract_pros_cons function needed anymore\n","\n","# --- Core Function to Process Product Name (REMOVED Pro/Con Steps) ---\n","async def analyze_product(product_name_query):\n","    \"\"\"\n","    Finds reviews, filters (relaxed), gets overall sentiment (HF),\n","    summarizes (HF), and formats result (NO Pros/Cons).\n","    \"\"\"\n","    global df # Access global dataframe\n","    global PRODUCT_NAME_COLUMN, REVIEW_TEXT_COLUMN, SUMMARY_COLUMN, RATING_COLUMN, ORIGINAL_SENTIMENT_COLUMN\n","\n","    if df is None or df.empty: logger.error(\"DataFrame 'df' is not available.\"); return \"Error: The review dataset is not loaded or is empty.\"\n","\n","    logger.info(f\"Received product query: '{product_name_query}'\"); analysis_start_time = time.time()\n","\n","    # 1. Prepare Query and Perform Matching (Same as before)\n","    product_name_query_normalized = product_name_query.lower().strip(); product_reviews_df = pd.DataFrame()\n","    try:\n","        if PRODUCT_NAME_COLUMN not in df.columns: raise KeyError(f\"Product name column '{PRODUCT_NAME_COLUMN}' not found.\")\n","        df_normalized_names = df[PRODUCT_NAME_COLUMN].str.lower().str.strip()\n","        match_mask = (df_normalized_names == product_name_query_normalized); product_reviews_df = df[match_mask].copy()\n","        logger.info(f\"Found {len(product_reviews_df)} reviews after matching.\")\n","    except Exception as e: logger.error(f\"Error during DataFrame filtering for '{product_name_query}': {e}\", exc_info=True); safe_query = escape_markdown_v2(product_name_query); return f\"‚ùå An internal error occurred while searching for the product: `{safe_query}`\"\n","    if product_reviews_df.empty: safe_query = escape_markdown_v2(product_name_query); return f\"‚ùå Sorry, I couldn't find any reviews for `{safe_query}`.\"\n","    matched_product_name = product_reviews_df[PRODUCT_NAME_COLUMN].iloc[0]; total_reviews_found = len(product_reviews_df)\n","    logger.info(f\"Processing {total_reviews_found} reviews for: '{matched_product_name}'.\")\n","\n","    # 2. Filter Fake Reviews \u0026 Collect Data (Uses RELAXED V2 filter)\n","    genuine_reviews_data = []; fake_count = 0\n","    for index, row in product_reviews_df.iterrows():\n","        review_text = row.get(REVIEW_TEXT_COLUMN, \"\"); summary_text = row.get(SUMMARY_COLUMN, \"\"); rating = row.get(RATING_COLUMN, None); original_sentiment = row.get(ORIGINAL_SENTIMENT_COLUMN, None)\n","        if not is_likely_fake(review_text, rating, original_sentiment):\n","            if (review_text and str(review_text).strip()) or (summary_text and str(summary_text).strip()): genuine_reviews_data.append({\"review_text\": str(review_text), \"summary_text\": str(summary_text), \"rating\": rating})\n","            else: fake_count +=1\n","        else: fake_count += 1\n","    num_genuine_reviews = len(genuine_reviews_data); logger.info(f\"Filtered {fake_count} reviews (using relaxed filter). Analyzing {num_genuine_reviews} genuine reviews.\")\n","    if not genuine_reviews_data: safe_matched_name = escape_markdown_v2(matched_product_name); return f\"Found {total_reviews_found} reviews for `{safe_matched_name}`, but all filtered out.\"\n","\n","    # --- Prepare lists ---\n","    genuine_review_texts = [item['review_text'] for item in genuine_reviews_data if item['review_text']]; valid_ratings = [item['rating'] for item in genuine_reviews_data if isinstance(item['rating'], (int, float)) and pd.notna(item['rating'])]\n","    # No need for genuine_summary_texts list anymore\n","\n","    # 3. Get Overall Sentiment (Hugging Face on Review text) - Same\n","    new_overall_sentiments = []\n","    if genuine_review_texts:\n","        logger.info(\"Starting overall sentiment analysis (HF)...\"); hf_start = time.time()\n","        for text in genuine_review_texts: new_overall_sentiments.append(get_sentiment(text)['label'])\n","        logger.info(f\"Overall sentiment analysis done in {time.time() - hf_start:.2f}s.\")\n","\n","    # 4. Generate Summary (Hugging Face on Review text) - Same\n","    summary_snippet = \"Could not generate summary.\"\n","    if genuine_review_texts:\n","        logger.info(\"Generating summary (HF)...\"); summ_start = time.time()\n","        full_genuine_review_text = \"\\n\".join(genuine_review_texts); summary_snippet = generate_summary(full_genuine_review_text, max_len=100, min_len=20)\n","        logger.info(f\"Summary generation done in {time.time() - summ_start:.2f}s.\")\n","\n","    # 5. Calculate Overall Verdict - Same\n","    verdict = calculate_overall_verdict(new_overall_sentiments)\n","\n","    # 6. Calculate Average Rating - Same\n","    average_rating = np.mean(valid_ratings) if valid_ratings else None; avg_rating_str = f\"{average_rating:.1f} / 5 ‚òÖ\" if average_rating is not None else \"N/A\"\n","\n","    # 7. *** Pro/Con Extraction SKIPPED ***\n","    logger.info(\"Skipping Pro/Con extraction as requested.\")\n","\n","    # 8. Format the Response (REMOVED Pro/Con Sections)\n","    safe_matched_name = escape_markdown_v2(matched_product_name); response = f\"üìä *Analysis for:* `{safe_matched_name}`\\n\\n\"; response += f\"‚≠ê *Avg\\\\. Rating \\\\(Genuine\\\\):* {escape_markdown_v2(avg_rating_str)}\\n\"; response += f\"‚öñÔ∏è *Overall Verdict \\\\(from Reviews\\\\):* {escape_markdown_v2(verdict)}\\n\"; response += f\"_(Based on {num_genuine_reviews} genuine entries out of {total_reviews_found} total found\\\\. {fake_count} filtered\\\\.)_\\n\\n\"\n","\n","    # --- REMOVED Pro Section ---\n","    # --- REMOVED Con Section ---\n","\n","    # --- Generated Summary Snippet ---\n","    formatted_summary = escape_markdown_v2(summary_snippet)\n","    response += f\"üìù *Generated Summary Snippet \\\\(Reviews\\\\):*\\n_{formatted_summary}_\\n\\n\" # Add extra newline for spacing\n","\n","    # --- Overall Sentiment Breakdown ---\n","    pos_count = new_overall_sentiments.count(\"Positive\"); neg_count = new_overall_sentiments.count(\"Negative\"); neu_count = new_overall_sentiments.count(\"Neutral\"); total_overall_sentiments = len(new_overall_sentiments) if new_overall_sentiments else 1\n","    response += f\"*Overall Sentiment Breakdown \\\\(Reviews\\\\):*\\n\"; response += f\"  üü¢ Positive: {pos_count} \\\\({pos_count/total_overall_sentiments:.0%}\\\\)\\n\"; response += f\"  üî¥ Negative: {neg_count} \\\\({neg_count/total_overall_sentiments:.0%}\\\\)\\n\"; response += f\"  ‚ö™ Neutral:  {neu_count} \\\\({neu_count/total_overall_sentiments:.0%}\\\\)\"\n","\n","    analysis_duration = time.time() - analysis_start_time; logger.info(f\"Analysis complete for '{matched_product_name}' in {analysis_duration:.2f}s. Response length: {len(response)}\")\n","    if len(response) \u003e 4096: logger.warning(f\"Response exceeds 4096 chars ({len(response)}). Truncating.\"); response = response[:4090] + \"\\\\.\\\\.\\\\.\"\n","    return response\n","\n","# --- Bot Command Handlers, Error Handler, run_bot (No changes needed) ---\n","# ... (Keep the start, help_command, handle_message, error_handler, and run_bot functions exactly as they were, including the asyncio import in run_bot) ...\n","\n","# --- Placeholder for other handlers/run_bot (use previous correct code) ---\n","async def start(update: telegram.Update, context: telegram.ext.ContextTypes.DEFAULT_TYPE):\n","    user = update.effective_user\n","    await update.message.reply_markdown_v2(\n","        rf\"Hi {user.mention_markdown_v2()}\\! üëã Send me an exact Product Name from the dataset and I'll analyze its reviews\\.\",\n","    )\n","\n","async def help_command(update: telegram.Update, context: telegram.ext.ContextTypes.DEFAULT_TYPE):\n","    help_text = ( # Updated help text - removed pro/con mention\n","        \"*How to use:*\\n\"\n","        \"1\\\\. Send me the *exact* Product Name\\\\.\\n\"\n","        \"2\\\\. I find reviews \u0026 summaries\\\\.\\n\"\n","        \"3\\\\. I filter fake reviews \\\\(relaxed\\\\)\\\\.\\n\"\n","        \"4\\\\. I get overall sentiment \\\\(from Reviews\\\\)\\\\.\\n\"\n","        \"5\\\\. I provide avg rating, verdict, and a *new* summary snippet \\\\(from Reviews\\\\)\\\\.\\n\\n\" # Removed Pro/Con\n","        \"_Exact name match needed\\\\!_\"\n","    )\n","    await update.message.reply_markdown_v2(help_text)\n","\n","async def handle_message(update: telegram.Update, context: telegram.ext.ContextTypes.DEFAULT_TYPE):\n","    user_input = update.message.text\n","    chat_id = update.effective_chat.id\n","    logger.info(f\"Received message from chat {chat_id}: {user_input}\")\n","\n","    product_name = user_input.strip()\n","    if not product_name:\n","        await update.message.reply_text(\"‚ö†Ô∏è Please send a product name.\")\n","        return\n","\n","    processing_msg = None\n","    safe_product_name_escaped = escape_markdown_v2(product_name)\n","\n","    try:\n","        processing_msg = await update.message.reply_text(\n","            f\"‚è≥ Analyzing reviews for `{safe_product_name_escaped}`\\\\.\\\\.\\\\.\",\n","            parse_mode=telegram.constants.ParseMode.MARKDOWN_V2\n","        )\n","    except telegram.error.BadRequest as e:\n","        logger.error(f\"Failed to send 'Analyzing...' message for '{product_name}' using MarkdownV2: {e}\")\n","        try:\n","            processing_msg = await update.message.reply_text(\n","                f\"‚è≥ Analyzing reviews for '{product_name}'...\"\n","            )\n","        except Exception as fallback_e:\n","            logger.error(f\"Failed to send even plain text 'Analyzing...' message: {fallback_e}\")\n","            try:\n","                await update.message.reply_text(\"‚ö†Ô∏è Error initiating analysis. Please try again.\")\n","            except Exception:\n","                pass\n","            return\n","    except Exception as e:\n","        logger.error(f\"Unexpected error sending 'Analyzing...' message: {e}\", exc_info=True)\n","        try:\n","            await update.message.reply_text(\"‚ö†Ô∏è Error initiating analysis. Please try again.\")\n","        except Exception:\n","            pass\n","        return\n","\n","    if not processing_msg:\n","        logger.error(\"Failed to create the processing message. Aborting analysis.\")\n","        return\n","\n","    handler_start_time = time.time()\n","    analysis_result = await analyze_product(product_name)\n","    handler_duration = time.time() - handler_start_time\n","    logger.info(f\"analyze_product for '{product_name}' took {handler_duration:.2f} seconds (within handler).\")\n","\n","    try:\n","        await processing_msg.edit_text(\n","            analysis_result,\n","            parse_mode=telegram.constants.ParseMode.MARKDOWN_V2\n","        )\n","    except telegram.error.BadRequest as e:\n","        error_message_lower = str(e).lower()\n","\n","        if \"message is not modified\" in error_message_lower:\n","            logger.warning(f\"Message not modified for '{product_name}'.\")\n","        elif any(err_str in error_message_lower for err_str in [\n","            \"can't parse entities\", \"unmatched closing tag\", \"wrong closing tag\",\n","            \"too long\", \"is reserved and must be escaped\"\n","        ]):\n","            logger.warning(f\"MarkdownV2 parsing failed for result of '{product_name}'. Retrying with plain text. Error: {e}\")\n","            plain_result = re.sub(r'[\\\\*_`~\\[\\]()#+=|{}.!-]', '', analysis_result)\n","            if len(plain_result) \u003e 4096:\n","                plain_result = plain_result[:4090] + \"...\"\n","            try:\n","                await processing_msg.edit_text(plain_result)\n","            except Exception as final_e:\n","                logger.error(f\"Failed to send even plain text result for '{product_name}': {final_e}\")\n","                try:\n","                    await processing_msg.edit_text(\"‚ùå An error occurred displaying the results (plain text fallback failed).\")\n","                except Exception:\n","                    pass\n","        else:\n","            logger.error(f\"Telegram API BadRequest sending result for '{product_name}': {e}\", exc_info=True)\n","            try:\n","                await processing_msg.edit_text(\"‚ùå An error occurred sending the analysis (API Error).\")\n","            except Exception:\n","                pass\n","    except Exception as e:\n","        logger.error(f\"Unexpected error editing message for '{product_name}': {e}\", exc_info=True)\n","        try:\n","            await processing_msg.edit_text(\"‚ùå An unexpected error occurred displaying the results.\")\n","        except Exception:\n","            pass\n","\n","\n","async def error_handler(update: object, context: telegram.ext.ContextTypes.DEFAULT_TYPE):\n","    # (Same implementation as before)\n","    logger.error(msg=\"Exception while handling an update:\", exc_info=context.error)\n","    if isinstance(context.error, telegram.error.Conflict): logger.warning(\"Conflict error detected.\")\n","    if isinstance(context.error, (telegram.error.NetworkError)) and 'Updater' in str(context.error): logger.error(f\"Network error during polling: {context.error}\")\n","    if update and isinstance(update, telegram.Update) and update.effective_message:\n","         try:\n","             if not isinstance(context.error, telegram.error.BadRequest) or \\\n","                all(indicator not in str(context.error).lower() for indicator in [\"message is not modified\", \"can't parse\", \"unmatched\", \"wrong tag\"]):\n","                   await update.effective_message.reply_text(\"‚ùå Oops! Something went wrong. Please try again.\")\n","         except Exception as e: logger.error(f\"Failed to send generic error message to user during error handling: {e}\")\n","\n","async def run_bot():\n","    # (Same implementation as before, including the corrected shutdown logic)\n","    import asyncio; from telegram.ext import Application, CommandHandler, MessageHandler, filters; import telegram\n","    if BOT_TOKEN == \"YOUR_BOT_TOKEN\" or not BOT_TOKEN or len(BOT_TOKEN.split(':')) != 2: print(\"[-] ERROR: BOT_TOKEN invalid!\"); logger.error(\"Bot Token is invalid or missing!\"); return\n","    print(\"[+] Initializing Telegram Bot Application...\"); application = Application.builder().token(BOT_TOKEN).build(); application.add_handler(CommandHandler(\"start\", start)); application.add_handler(CommandHandler(\"help\", help_command)); application.add_handler(MessageHandler(filters.TEXT \u0026 ~filters.COMMAND, handle_message)); application.add_error_handler(error_handler)\n","    try:\n","        print(\"[+] Initializing application...\"); await application.initialize(); logger.info(\"Application initialized.\")\n","        print(\"[+] Starting background tasks (polling)...\"); await application.start(); await application.updater.start_polling(allowed_updates=telegram.Update.ALL_TYPES); logger.info(\"Application started and polling initiated.\")\n","        print(\"\\n[+] Bot is now running!\"); print(\"[+] Send commands or product names to your bot on Telegram.\"); print(\"[+] Stop this cell execution in Colab/Jupyter (or Ctrl+C) to stop the bot.\"); await asyncio.Future() # Keep running\n","    except telegram.error.InvalidToken: logger.error(\"CRITICAL ERROR: Invalid Token.\", exc_info=False); print(\"\\n[!!!] ERROR: Invalid Token!\")\n","    except telegram.error.NetworkError as ne: logger.error(f\"CRITICAL Network error: {ne}\", exc_info=True); print(f\"\\n[!!!] ERROR: Network error: {ne}\")\n","    except telegram.error.Conflict as conf_err: logger.error(f\"CRITICAL Conflict: {conf_err}\", exc_info=True); print(f\"\\n[!!!] ERROR: Conflict: {conf_err}\")\n","    except (KeyboardInterrupt, SystemExit, asyncio.CancelledError): logger.info(\"Stop signal received.\"); print(\"\\n[!] Bot stopping...\")\n","    except Exception as e: logger.error(f\"Unexpected error during bot run: {e}\", exc_info=True); print(f\"\\n[!!!] Bot stopping due to error: {e}\")\n","    finally:\n","        logger.info(\"Initiating shutdown...\"); print(\"[+] Shutting down bot...\")\n","        if 'application' in locals() and application:\n","            if application.updater and application.updater.running: print(\"    - Stopping updater polling...\"); await application.updater.stop(); logger.info(\"Updater stopped.\")\n","            if application.running: print(\"    - Stopping application handlers...\"); await application.stop(); logger.info(\"Application stopped.\")\n","            print(\"    - Shutting down application resources...\"); await application.shutdown(); logger.info(\"Application shut down.\")\n","        print(\"[+] Bot shutdown complete.\")\n","\n","# --- (End of Step 6 Code Block) ---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hQlnBHJHxofE"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Bot Execution ---\n","[i] Dataframe loaded.\n","[i] Sentiment analysis pipeline (Hugging Face) ready.\n","[i] Summarization pipeline (Hugging Face) ready.\n","[i] Awaiting bot execution...\n","[+] Initializing Telegram Bot Application...\n","[+] Initializing application...\n","[+] Starting background tasks (polling)...\n","\n","[+] Bot is now running!\n","[+] Send commands or product names to your bot on Telegram.\n","[+] Stop this cell execution in Colab/Jupyter (or Ctrl+C) to stop the bot.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:__main__:MarkdownV2 parsing failed for result of 'Crompton 75 L Desert Air Cooler??????(White, Teal, ACGC-DAC751)'. Retrying with plain text. Error: Can't parse entities: character '(' is reserved and must be escaped with the preceding '\\'\n"]},{"name":"stdout","output_type":"stream","text":["\n","[!] Bot stopping...\n","[+] Shutting down bot...\n","    - Stopping updater polling...\n","    - Stopping application handlers...\n","    - Shutting down application resources...\n","[+] Bot shutdown complete.\n","--- Bot Execution Block Finished ---\n"]}],"source":["# %% [code]\n","# STEP 7 CODE BLOCK (Removed NLTK check)\n","\n","# --- Start the Bot ---\n","\n","if __name__ == '__main__':\n","     print(\"\\n--- Starting Bot Execution ---\")\n","     # Make sure data is loaded and pipelines are potentially ready\n","     if 'df' in globals() and df is not None and not df.empty:\n","         print(\"[i] Dataframe loaded.\")\n","         # Check if HF pipelines are loaded\n","         if 'sentiment_pipeline' in globals() and sentiment_pipeline:\n","             print(\"[i] Sentiment analysis pipeline (Hugging Face) ready.\")\n","         else:\n","             print(\"[!] Warning: HF Sentiment pipeline not loaded. Overall sentiment results will be 'Neutral'.\")\n","         if 'summarizer' in globals() and summarizer:\n","             print(\"[i] Summarization pipeline (Hugging Face) ready.\")\n","         else:\n","             print(\"[!] Warning: Summarization pipeline not loaded. Summaries will be basic.\")\n","         # No Pro/Con extraction, so no NLTK check needed here\n","\n","         # Call the async function\n","         print(\"[i] Awaiting bot execution...\")\n","         try:\n","            await run_bot() # Calls the function containing the main loop and shutdown logic\n","         except RuntimeError as e:\n","             if \"cannot schedule new futures after shutdown\" in str(e).lower():\n","                 print(\"[!] Event loop was likely already shut down.\")\n","                 logger.warning(\"RuntimeError related to event loop shutdown caught.\")\n","             else:\n","                 print(f\"[!!!] Runtime Error occurred while awaiting run_bot: {e}\")\n","                 logger.error(\"RuntimeError awaiting run_bot\", exc_info=True)\n","         except Exception as e:\n","             print(f\"[!!!] An unexpected error occurred while awaiting run_bot: {e}\")\n","             logger.error(\"Error awaiting run_bot\", exc_info=True)\n","\n","     else:\n","         print(\"[-] ERROR: Dataframe 'df' not loaded or empty. Cannot start the bot.\")\n","         print(\"[-] Please ensure Step 1 runs successfully and the file exists.\")\n","         logger.error(\"Attempted to start bot without loaded data.\")\n","\n","     print(\"--- Bot Execution Block Finished ---\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMC4nKHEeFFWQMyboDMX0OK","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}